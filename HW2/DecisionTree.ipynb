{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f58bab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.label = None  # label attribute for node labels\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "        \n",
    "        \n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2):\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.root=None\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)\n",
    "        \n",
    "    def _grow_tree(self, X, y, best=-1): # 'best' is the best_ratio in loop\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # check stopping criteria\n",
    "        if (n_labels==1 or \\\n",
    "            n_samples < self.min_samples_split or \\\n",
    "            best==0):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # find best split\n",
    "        best_feat, best_thr, best_ratio = self._best_split(X, y)\n",
    "        \n",
    "        #create child node\n",
    "        left_idxs, right_idxs = self._split(X[:, best_feat], best_thr)\n",
    "        left = self._grow_tree(X[left_idxs, :], y[left_idxs], best_ratio)\n",
    "        right = self._grow_tree(X[right_idxs, :], y[right_idxs], best_ratio)\n",
    "        \n",
    "        return Node(best_feat, best_thr, left, right)\n",
    "    \n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain_ratio = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "        \n",
    "        for idx in range(X.shape[1]):\n",
    "            X_col = X[:,idx]\n",
    "            thresholds = np.unique(X_col)\n",
    "            \n",
    "            for thres in thresholds:\n",
    "                # compute H_D(S)\n",
    "                prob_left = np.sum(X_col >= thres)/len(X_col) # P(left)\n",
    "                prob_right = 1 - prob_left # P(right)\n",
    "                if (prob_left==0 or prob_right==0):   # skip slpits with zero split info\n",
    "                    gain_ratio = 0    # manually makes it 0\n",
    "                else:\n",
    "                    H_S = -prob_left*np.log2(prob_left) -prob_right*np.log2(prob_right)\n",
    "                \n",
    "                    # compute GainRatio\n",
    "                    gain_ratio = self._InfoGain(X_col, y, thres)/H_S\n",
    "                \n",
    "                if gain_ratio > best_gain_ratio:\n",
    "                    best_gain_ratio = gain_ratio\n",
    "                    split_idx = idx\n",
    "                    split_threshold = thres\n",
    "                    \n",
    "        return split_idx, split_threshold, best_gain_ratio\n",
    "    \n",
    "    \n",
    "    def _InfoGain(self, X_col, y, thres):\n",
    "        # parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        \n",
    "        # create child\n",
    "        left_idx, right_idx = self._split(X_col, thres)\n",
    "        \n",
    "        if len(left_idx)==0 or len(right_idx)==0: # one of child node is empty\n",
    "            return 0\n",
    "        \n",
    "        # child entropy\n",
    "        n = len(y)\n",
    "        n_left, n_right = len(left_idx), len(right_idx)\n",
    "        left_entropy, right_entropy = self._entropy(y[left_idx]), self._entropy(y[right_idx])\n",
    "        child_entropy = n_left/n * left_entropy + n_right/n * right_entropy\n",
    "        \n",
    "        #InfoGain\n",
    "        InfoGain = parent_entropy - child_entropy\n",
    "        return InfoGain\n",
    "    \n",
    "    def _split(self, X_col, thres):\n",
    "        left_idxs = np.argwhere(X_col >= thres).flatten()\n",
    "        right_idxs = np.argwhere(X_col < thres).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "    \n",
    "    def _entropy(self, y):    \n",
    "        prob1 = np.sum(y==1)/len(y) # y=1\n",
    "        prob0 = 1 - prob1 # y=0\n",
    "        if prob1==0 or prob0==0: #when the node is empty or pure\n",
    "            return 0\n",
    "        else:\n",
    "            return(-prob0*np.log2(prob0) -prob1*np.log2(prob1))\n",
    "        \n",
    "    def _most_common_label(self, y):\n",
    "        if (sum(y==1) >= sum(y==0)): #if no majority class, return y=1\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    ##  prediction  \n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature] >= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    ## tree plot\n",
    "    def visualize_tree(self):\n",
    "        def visualize_tree_recursive(node, depth=0):\n",
    "            indent = \"  \" * depth\n",
    "            if node.is_leaf_node():\n",
    "                print(indent + f\"Leaf: Class {node.value}\")\n",
    "            else:\n",
    "                print(indent + f\"X{node.feature+1} >= {node.threshold}\")\n",
    "                visualize_tree_recursive(node.left, depth + 1)\n",
    "                visualize_tree_recursive(node.right, depth + 1)\n",
    "\n",
    "        visualize_tree_recursive(self.root)\n",
    "        \n",
    "    \n",
    "    ## boundary plot\n",
    "    def plot_decision_boundary(self, X, y, feature_names=['feature 1', 'feature 2'], class_names=['0','1']):\n",
    "        if X.shape[1] != 2:\n",
    "            raise ValueError(\"This method only for visualizing 2-D data.\")\n",
    "\n",
    "        if self.root is None:\n",
    "            raise ValueError(\"Decision tree needs training.\")\n",
    "\n",
    "        # Create meshgrid for the feature space\n",
    "        x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "        y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "        # Make predictions for all points in the meshgrid\n",
    "        Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot decision boundary\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.contourf(xx, yy, Z, cmap='magma', alpha=0.8)\n",
    "        \n",
    "\n",
    "        # Plot points for each class\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap='rainbow', edgecolor='k', s=20)\n",
    "\n",
    "        plt.xlabel('X1')\n",
    "        plt.ylabel('X2')\n",
    "        plt.title('Decision Boundary of Decision Tree')\n",
    "        \n",
    "        # remove axis\n",
    "        if feature_names:\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    ## count nodes number (we count leaf as a node ('leaf node' as defined in Wiki))\n",
    "    def count_nodes(self):\n",
    "        def count_nodes_recursive(node):\n",
    "            if node is None:\n",
    "                return 0\n",
    "            return 1 + count_nodes_recursive(node.left) + count_nodes_recursive(node.right)\n",
    "        \n",
    "        return count_nodes_recursive(self.root)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c155720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
